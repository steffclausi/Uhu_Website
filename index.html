<script type="module">
        // --- Globale Konfiguration (nur was fÃ¼r die UI gebraucht wird) ---
        const MODEL_PATH = './uhu_model_js/model.json';
        const MAX_CLIPS_TO_SHOW = 20;

        const AUDIO_CONFIG = {
            SAMPLE_RATE: 16000,
        };

        // --- UI-Elemente (bleibt gleich) ---
        const fileUploader = document.getElementById('file-uploader');
        const fileListDiv = document.getElementById('file-list');
        const paramsSection = document.getElementById('parameters-section');
        const overlapSlider = document.getElementById('overlap-slider');
        const overlapValue = document.getElementById('overlap-value');
        const mergeCheckbox = document.getElementById('merge-checkbox');
        const startBtn = document.getElementById('start-analysis-btn');
        const analysisProgress = document.getElementById('analysis-progress');
        const progressText = document.getElementById('progress-text');
        const progressBar = document.getElementById('progress-bar');
        const resultsSection = document.getElementById('results-section');
        const resultsTitle = document.getElementById('results-title');
        const resultsSummary = document.getElementById('results-summary');
        const resultsGrid = document.getElementById('results-grid');

        let uploadedFiles = [];
        let analysisWorker = null; // Variable fÃ¼r unseren Worker

        // --- Event Listeners (bleiben gleich) ---
        fileUploader.addEventListener('change', (e) => handleFiles(e.target.files));
        const dropZone = fileUploader.closest('.border-dashed');
        dropZone.addEventListener('dragover', (e) => {
            e.preventDefault();
            e.stopPropagation();
            dropZone.classList.add('border-indigo-500', 'bg-indigo-50');
        });
        dropZone.addEventListener('dragleave', (e) => {
            e.preventDefault();
            e.stopPropagation();
            dropZone.classList.remove('border-indigo-500', 'bg-indigo-50');
        });
        dropZone.addEventListener('drop', (e) => {
            e.preventDefault();
            e.stopPropagation();
            dropZone.classList.remove('border-indigo-500', 'bg-indigo-50');
            handleFiles(e.dataTransfer.files);
        });
        overlapSlider.addEventListener('input', (e) => {
            overlapValue.textContent = `${e.target.value}%`;
        });
        startBtn.addEventListener('click', runAnalysis);

        function handleFiles(files) {
            uploadedFiles = Array.from(files);
            if (uploadedFiles.length > 0) {
                fileListDiv.innerHTML = `<h3 class="font-medium text-gray-700">AusgewÃ¤hlte Dateien:</h3><ul class="list-disc list-inside text-sm text-gray-600">${uploadedFiles.map(f => `<li>${f.name}</li>`).join('')}</ul>`;
                paramsSection.classList.remove('hidden');
            } else {
                fileListDiv.innerHTML = '';
                paramsSection.classList.add('hidden');
            }
        }
        
        // ========================================================================
        // NEUE, SCHLANKE runAnalysis FUNKTION
        // ========================================================================

        async function runAnalysis() {
            if (uploadedFiles.length === 0) {
                alert("Bitte wÃ¤hlen Sie zuerst Audiodateien aus.");
                return;
            }

            // UI fÃ¼r den Start vorbereiten
            startBtn.disabled = true;
            startBtn.classList.add('opacity-50', 'cursor-not-allowed');
            analysisProgress.classList.remove('hidden');
            resultsSection.classList.add('hidden');
            resultsGrid.innerHTML = '';
            resultsSummary.innerHTML = '';
            progressText.textContent = 'Initialisiere Analyse...';
            progressBar.style.width = '0%';

            // Worker erstellen und starten
            analysisWorker = new Worker('analysis_worker.js');

            // Listener fÃ¼r Nachrichten VOM Worker
            analysisWorker.onmessage = (event) => {
                const { type, data } = event.data;

                switch (type) {
                    case 'progress':
                        progressText.textContent = data.text;
                        if (data.progress) {
                             progressBar.style.width = `${data.progress}%`;
                        }
                        break;
                    case 'done':
                        displayResults(data); // Ergebnis anzeigen
                        terminateWorker();
                        break;
                    case 'error':
                        console.error("Fehler vom Worker erhalten:", data);
                        progressText.textContent = `Ein Fehler ist aufgetreten: ${data}`;
                        alert(`Ein Analysefehler ist aufgetreten: ${data}`);
                        terminateWorker();
                        break;
                }
            };

            // Listener fÃ¼r Fehler im Worker
            analysisWorker.onerror = (error) => {
                console.error("Ein kritischer Fehler ist im Worker aufgetreten:", error);
                progressText.textContent = `Ein kritischer Fehler ist aufgetreten: ${error.message}`;
                terminateWorker();
            };

            // Parameter sammeln
            const params = {
                threshold: 0.5,
                overlapPercent: parseInt(overlapSlider.value),
                shouldMerge: mergeCheckbox.checked,
            };

            // Nachricht AN den Worker senden, um die Analyse zu starten
            analysisWorker.postMessage({
                files: uploadedFiles,
                params: params,
                modelPath: MODEL_PATH
            });
        }
        
        function terminateWorker() {
             if (analysisWorker) {
                analysisWorker.terminate();
                analysisWorker = null;
            }
            startBtn.disabled = false;
            startBtn.classList.remove('opacity-50', 'cursor-not-allowed');
            // Kurze VerzÃ¶gerung, damit der "Abgeschlossen"-Text sichtbar ist
            setTimeout(() => {
                analysisProgress.classList.add('hidden');
                progressBar.style.width = '0%';
            }, 2000);
        }

        // --- Ergebnisdarstellung (bleibt grÃ¶ÃŸtenteils gleich) ---
        
        // Die `audioToMelspectrogram`-Funktion wird hier nur noch fÃ¼r die *Visualisierung* gebraucht.
        // DafÃ¼r mÃ¼ssen wir sie hier behalten, aber sie ist nicht mehr Teil der Analyse-Pipeline.
        // Alternative: Man kÃ¶nnte auch das Spektrogramm-Array vom Worker zurÃ¼cksenden.
        // Der Einfachheit halber berechnen wir es hier neu.
        
        let localModelForViz = null; // Wir brauchen tfjs auch hier, nur fÃ¼r die Visualisierung

        async function getSpecForViz(audioClip) {
            // Eine abgespeckte Version, nur fÃ¼r die Visualisierung
            if (!window.tf) return null; // Fallback, falls tfjs nicht geladen ist
            
            // Erstellen Sie die Vorverarbeitungsfunktionen hier erneut, aber nur fÃ¼r die Visualisierung
             function audioToMelspectrogramForViz(y) {
                const DURATION = 3;
                const TARGET_SAMPLES = 16000 * DURATION;
                const N_FFT = 1024;
                const HOP_LENGTH = 512;
                const N_MELS = 64;

                if (y.length > TARGET_SAMPLES) {
                    y = y.slice(0, TARGET_SAMPLES);
                } else if (y.length < TARGET_SAMPLES) {
                    const padding = new Float32Array(TARGET_SAMPLES - y.length).fill(0);
                    const newY = new Float32Array(TARGET_SAMPLES); newY.set(y); newY.set(padding, y.length); y = newY;
                }
                return tf.tidy(() => {
                    const stft = tf.signal.stft(tf.tensor1d(y), N_FFT, HOP_LENGTH);
                    const powerSpectrogram = tf.square(tf.abs(stft));
                    const melMatrix = createMelFilterbank(N_MELS, N_FFT / 2 + 1, 16000, 0, 16000 / 2);
                    const melSpectrogram = tf.matMul(powerSpectrogram, melMatrix);
                    const logMelSpectrogram = tf.log(melSpectrogram.add(1e-6));
                    return logMelSpectrogram.expandDims(-1);
                });
            }
            function createMelFilterbank(numMelBins, numSpectrogramBins, sampleRate, lowerEdgeHz, upperEdgeHz) {
                const hzToMel = (hz) => 1127.0 * Math.log(1.0 + hz / 700.0);
                const melToHz = (mel) => 700.0 * (Math.exp(mel / 1127.0) - 1.0);
                const lowerMel = hzToMel(lowerEdgeHz);
                const upperMel = hzToMel(upperEdgeHz);
                const melPoints = tf.linspace(lowerMel, upperMel, numMelBins + 2).arraySync();
                const hzPoints = melPoints.map(melToHz);
                const spectrogramBinHz = sampleRate / 2.0 / (numSpectrogramBins - 1);
                const spectrogramBinEdges = Array.from({ length: numSpectrogramBins }, (_, i) => i * spectrogramBinHz);
                const melWeights = tf.buffer([numSpectrogramBins, numMelBins]);
                for (let i = 0; i < numMelBins; i++) {
                    const leftEdge = hzPoints[i], center = hzPoints[i+1], rightEdge = hzPoints[i+2];
                    for (let j = 0; j < numSpectrogramBins; j++) {
                        const specHz = spectrogramBinEdges[j];
                        let weight = 0.0;
                        if (specHz >= leftEdge && specHz <= center) weight = (specHz - leftEdge) / (center - leftEdge);
                        else if (specHz > center && specHz <= rightEdge) weight = (rightEdge - specHz) / (rightEdge - center);
                        if(weight > 0) melWeights.set(weight, j, i);
                    }
                }
                return melWeights.toTensor();
            }

            return audioToMelspectrogramForViz(audioClip);
        }

        // --- Alle weiteren Funktionen (createWavBlob, displayResults, drawSpectrogram) bleiben unverÃ¤ndert ---
        // ... (Kopieren Sie den Rest Ihrer Funktionen von createWavBlob bis zum Ende hierher)
        
        function createWavBlob(samples, sampleRate) {
            const buffer = new ArrayBuffer(44 + samples.length * 2);
            const view = new DataView(buffer);
            const writeString = (view, offset, string) => { for (let i = 0; i < string.length; i++) { view.setUint8(offset + i, string.charCodeAt(i)); } };
            writeString(view, 0, 'RIFF');
            view.setUint32(4, 36 + samples.length * 2, true);
            writeString(view, 8, 'WAVE');
            writeString(view, 12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, 1, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * 2, true);
            view.setUint16(32, 2, true);
            view.setUint16(34, 16, true);
            writeString(view, 36, 'data');
            view.setUint32(40, samples.length * 2, true);
            let offset = 44;
            for (let i = 0; i < samples.length; i++, offset += 2) {
                const s = Math.max(-1, Math.min(1, samples[i]));
                view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
            }
            return new Blob([view], { type: 'audio/wav' });
        }

        function displayResults(events) {
            resultsSection.classList.remove('hidden');
            resultsTitle.textContent = `2. Ergebnisse: ${events.length} Uhu-Rufe gefunden`;
            if (events.length === 0) {
                resultsSummary.innerHTML = `<div class="bg-blue-100 border-l-4 border-blue-500 text-blue-700 p-4 rounded-md" role="alert"><p>Es wurden keine Ereignisse Ã¼ber dem eingestellten Schwellenwert gefunden.</p></div>`;
                return;
            }
            events.sort((a, b) => b.prob - a.prob);
            const csvContent = "data:text/csv;charset=utf-8," + "file,start_s,end_s,probability\n" + events.map(e => `${e.file},${(e.start / AUDIO_CONFIG.SAMPLE_RATE).toFixed(2)},${(e.end / AUDIO_CONFIG.SAMPLE_RATE).toFixed(2)},${e.prob.toFixed(3)}`).join("\n");
            const encodedUri = encodeURI(csvContent);
            resultsSummary.innerHTML = `<a href="${encodedUri}" download="uhu_events.csv" class="inline-block bg-green-600 text-white font-bold py-2 px-4 rounded-lg hover:bg-green-700 transition-colors">ðŸ“„ Alle ${events.length} Erkennungen als CSV herunterladen</a>`;
            const clipsToShow = events.slice(0, MAX_CLIPS_TO_SHOW);
            resultsGrid.innerHTML = `<h3 class="col-span-full text-xl font-bold text-gray-800 mt-6 mb-2">Erkannte Clips (Top ${clipsToShow.length})</h3>`;
            clipsToShow.forEach(event => {
                const card = document.createElement('div');
                card.className = 'bg-gray-50 p-4 rounded-lg shadow';
                const specCanvas = document.createElement('canvas');
                specCanvas.width = 200;
                specCanvas.height = 128;
                const audio = new Audio();
                const blob = createWavBlob(event.audioClip, AUDIO_CONFIG.SAMPLE_RATE);
                audio.src = URL.createObjectURL(blob);
                audio.controls = true;
                audio.className = 'w-full mt-2';
                card.innerHTML = `
                    <p class="text-sm font-medium truncate" title="${event.file}">${event.file}</p>
                    <p class="text-xs text-indigo-600 font-bold">Wahrscheinlichkeit: ${(event.prob * 100).toFixed(1)}%</p>
                `;
                card.appendChild(specCanvas);
                card.appendChild(audio);
                resultsGrid.appendChild(card);
                const specTensorForViz = getSpecForViz(event.audioClip);
                if (specTensorForViz) {
                    drawSpectrogram(specTensorForViz, specCanvas);
                    tf.dispose(specTensorForViz);
                }
            });
        }

        function drawSpectrogram(spec3D, canvas) {
            tf.tidy(() => {
                const spec2D = spec3D.squeeze();
                const specTransposed = spec2D.transpose();
                const ctx = canvas.getContext('2d');
                const [height, width] = specTransposed.shape;
                const canvasWidth = canvas.width, canvasHeight = canvas.height;
                const specArray = specTransposed.arraySync();
                let minVal = Infinity, maxVal = -Infinity;
                for(let i=0; i<height; i++) { for(let j=0; j<width; j++) { if(specArray[i][j] < minVal) minVal = specArray[i][j]; if(specArray[i][j] > maxVal) maxVal = specArray[i][j]; } }
                const range = maxVal - minVal;
                const colWidth = canvasWidth / width, rowHeight = canvasHeight / height;
                const viridis = [ [68, 1, 84], [72, 40, 120], [62, 74, 137], [49, 104, 142], [38, 130, 142], [31, 158, 137], [53, 183, 121], [109, 205, 89], [180, 222, 44], [253, 231, 37] ];
                const getColor = (value) => {
                    const i = Math.min(Math.max(Math.floor(value * (viridis.length - 1)), 0), viridis.length - 2);
                    const t = value * (viridis.length - 1) - i;
                    const r = Math.floor(viridis[i][0] + t * (viridis[i+1][0] - viridis[i][0]));
                    const g = Math.floor(viridis[i][1] + t * (viridis[i+1][1] - viridis[i][1]));
                    const b = Math.floor(viridis[i][2] + t * (viridis[i+1][2] - viridis[i][2]));
                    return `rgb(${r},${g},${b})`;
                };
                ctx.clearRect(0, 0, canvasWidth, canvasHeight);
                for (let x = 0; x < width; x++) {
                    for (let y = 0; y < height; y++) {
                        const value = specArray[y][x];
                        const normalized = (value - minVal) / range;
                        ctx.fillStyle = getColor(normalized);
                        ctx.fillRect(x * colWidth, canvasHeight - (y + 1) * rowHeight, colWidth, rowHeight);
                    }
                }
            });
        }
    </script>
