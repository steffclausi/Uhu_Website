<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Uhu-Ruf-Analyse</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.20.0/dist/tf.min.js"></script>
</head>
<body class="bg-gray-100 font-sans p-8">

    <div class="max-w-4xl mx-auto bg-white rounded-xl shadow-lg p-8 space-y-6">
        <header>
            <h1 class="text-4xl font-bold text-gray-800">ü¶â Uhu-Ruf-Detektor</h1>
            <p class="text-gray-600 mt-2">Laden Sie eine oder mehrere Audiodateien hoch, um sie auf die Rufe des Uhus (Bubo bubo) zu analysieren.</p>
        </header>

        <div id="upload-section">
            <h2 class="text-2xl font-semibold text-gray-700 mb-3">1. Dateien ausw√§hlen</h2>
            <div class="border-2 border-dashed border-gray-300 rounded-lg p-6 text-center cursor-pointer hover:border-indigo-500 hover:bg-indigo-50 transition-colors">
                <input type="file" id="file-uploader" multiple accept="audio/*" class="hidden">
                <label for="file-uploader" class="cursor-pointer">
                    <p class="text-indigo-600 font-semibold">Klicken Sie hier zum Hochladen</p>
                    <p class="text-sm text-gray-500 mt-1">oder ziehen Sie Ihre Dateien per Drag & Drop hierher</p>
                </label>
            </div>
            <div id="file-list" class="mt-4"></div>
        </div>

        <div id="parameters-section" class="hidden">
            <h2 class="text-2xl font-semibold text-gray-700 mb-3">2. Analyse-Einstellungen</h2>
            <div class="flex items-center space-x-4">
                <label for="overlap-slider" class="font-medium text-gray-700">√úberlappung:</label>
                <input id="overlap-slider" type="range" min="0" max="90" value="50" class="w-full">
                <span id="overlap-value" class="font-mono text-indigo-600 w-12 text-center">50%</span>
            </div>
            <div class="flex items-center space-x-2 mt-4">
                <input type="checkbox" id="merge-checkbox" checked class="h-4 w-4 rounded border-gray-300 text-indigo-600 focus:ring-indigo-500">
                <label for="merge-checkbox" class="text-gray-700">√úberlappende Erkennungen zusammenf√ºhren</label>
            </div>
            <button id="start-analysis-btn" class="mt-6 w-full bg-indigo-600 text-white font-bold py-3 px-6 rounded-lg hover:bg-indigo-700 transition-colors shadow-md">
                Analyse starten
            </button>
        </div>
        
        <div id="analysis-progress" class="hidden">
            <h2 class="text-2xl font-semibold text-gray-700">Analyse l√§uft...</h2>
            <p id="progress-text" class="text-gray-600">Initialisiere...</p>
            <div class="w-full bg-gray-200 rounded-full h-2.5 mt-2">
                <div id="progress-bar" class="bg-indigo-600 h-2.5 rounded-full" style="width: 0%"></div>
            </div>
        </div>

        <div id="results-section" class="hidden">
            <h2 id="results-title" class="text-2xl font-semibold text-gray-700 mb-3"></h2>
            <div id="results-summary" class="mb-6"></div>
            <div id="results-grid" class="grid grid-cols-1 sm:grid-cols-2 md:grid-cols-3 lg:grid-cols-4 gap-4">
                </div>
        </div>

    </div>

    <script type="module">
        // Dein gesamter JavaScript-Code kommt hier rein...
        document.addEventListener('DOMContentLoaded', () => {
            // --- Globale Konfiguration (nur was f√ºr die UI gebraucht wird) ---
            const MODEL_PATH = './uhu_model_js/model.json';
            const MAX_CLIPS_TO_SHOW = 20;

            const AUDIO_CONFIG = {
                SAMPLE_RATE: 16000,
            };

            // --- UI-Elemente (bleibt gleich) ---
            const fileUploader = document.getElementById('file-uploader');
            const fileListDiv = document.getElementById('file-list');
            const paramsSection = document.getElementById('parameters-section');
            const overlapSlider = document.getElementById('overlap-slider');
            const overlapValue = document.getElementById('overlap-value');
            const mergeCheckbox = document.getElementById('merge-checkbox');
            const startBtn = document.getElementById('start-analysis-btn');
            const analysisProgress = document.getElementById('analysis-progress');
            const progressText = document.getElementById('progress-text');
            const progressBar = document.getElementById('progress-bar');
            const resultsSection = document.getElementById('results-section');
            const resultsTitle = document.getElementById('results-title');
            const resultsSummary = document.getElementById('results-summary');
            const resultsGrid = document.getElementById('results-grid');

            let uploadedFiles = [];
            let analysisWorker = null; // Variable f√ºr unseren Worker

            // --- Event Listeners (bleiben gleich) ---
            fileUploader.addEventListener('change', (e) => handleFiles(e.target.files));
            const dropZone = fileUploader.closest('.border-dashed');
            dropZone.addEventListener('dragover', (e) => {
                e.preventDefault();
                e.stopPropagation();
                dropZone.classList.add('border-indigo-500', 'bg-indigo-50');
            });
            dropZone.addEventListener('dragleave', (e) => {
                e.preventDefault();
                e.stopPropagation();
                dropZone.classList.remove('border-indigo-500', 'bg-indigo-50');
            });
            dropZone.addEventListener('drop', (e) => {
                e.preventDefault();
                e.stopPropagation();
                dropZone.classList.remove('border-indigo-500', 'bg-indigo-50');
                handleFiles(e.dataTransfer.files);
            });
            overlapSlider.addEventListener('input', (e) => {
                overlapValue.textContent = `${e.target.value}%`;
            });
            startBtn.addEventListener('click', runAnalysis);

            function handleFiles(files) {
                uploadedFiles = Array.from(files);
                if (uploadedFiles.length > 0) {
                    fileListDiv.innerHTML = `<h3 class="font-medium text-gray-700">Ausgew√§hlte Dateien:</h3><ul class="list-disc list-inside text-sm text-gray-600">${uploadedFiles.map(f => `<li>${f.name}</li>`).join('')}</ul>`;
                    paramsSection.classList.remove('hidden');
                } else {
                    fileListDiv.innerHTML = '';
                    paramsSection.classList.add('hidden');
                }
            }
            
            // ========================================================================
            // NEUE, SCHLANKE runAnalysis FUNKTION
            // ========================================================================

            async function runAnalysis() {
                if (uploadedFiles.length === 0) {
                    alert("Bitte w√§hlen Sie zuerst Audiodateien aus.");
                    return;
                }

                // UI f√ºr den Start vorbereiten
                startBtn.disabled = true;
                startBtn.classList.add('opacity-50', 'cursor-not-allowed');
                analysisProgress.classList.remove('hidden');
                resultsSection.classList.add('hidden');
                resultsGrid.innerHTML = '';
                resultsSummary.innerHTML = '';
                progressText.textContent = 'Initialisiere Analyse...';
                progressBar.style.width = '0%';

                // Worker erstellen und starten
                analysisWorker = new Worker('analysis_worker.js');

                // Listener f√ºr Nachrichten VOM Worker
                analysisWorker.onmessage = (event) => {
                    const { type, data } = event.data;

                    switch (type) {
                        case 'progress':
                            progressText.textContent = data.text;
                            if (data.progress) {
                                progressBar.style.width = `${data.progress}%`;
                            }
                            break;
                        case 'done':
                            displayResults(data); // Ergebnis anzeigen
                            terminateWorker();
                            break;
                        case 'error':
                            console.error("Fehler vom Worker erhalten:", data);
                            progressText.textContent = `Ein Fehler ist aufgetreten: ${data}`;
                            alert(`Ein Analysefehler ist aufgetreten: ${data}`);
                            terminateWorker();
                            break;
                    }
                };

                // Listener f√ºr Fehler im Worker
                analysisWorker.onerror = (error) => {
                    console.error("Ein kritischer Fehler ist im Worker aufgetreten:", error);
                    progressText.textContent = `Ein kritischer Fehler ist aufgetreten: ${error.message}`;
                    terminateWorker();
                };

                // Parameter sammeln
                const params = {
                    threshold: 0.5,
                    overlapPercent: parseInt(overlapSlider.value),
                    shouldMerge: mergeCheckbox.checked,
                };

                // Nachricht AN den Worker senden, um die Analyse zu starten
                analysisWorker.postMessage({
                    files: uploadedFiles,
                    params: params,
                    modelPath: MODEL_PATH
                });
            }
            
            function terminateWorker() {
                if (analysisWorker) {
                    analysisWorker.terminate();
                    analysisWorker = null;
                }
                startBtn.disabled = false;
                startBtn.classList.remove('opacity-50', 'cursor-not-allowed');
                // Kurze Verz√∂gerung, damit der "Abgeschlossen"-Text sichtbar ist
                setTimeout(() => {
                    analysisProgress.classList.add('hidden');
                    progressBar.style.width = '0%';
                }, 2000);
            }

            // --- Ergebnisdarstellung (bleibt gr√∂√ütenteils gleich) ---
            
            // Die `audioToMelspectrogram`-Funktion wird hier nur noch f√ºr die *Visualisierung* gebraucht.
            // Daf√ºr m√ºssen wir sie hier behalten, aber sie ist nicht mehr Teil der Analyse-Pipeline.
            // Alternative: Man k√∂nnte auch das Spektrogramm-Array vom Worker zur√ºcksenden.
            // Der Einfachheit halber berechnen wir es hier neu.
            
            let localModelForViz = null; // Wir brauchen tfjs auch hier, nur f√ºr die Visualisierung

            async function getSpecForViz(audioClip) {
                // Eine abgespeckte Version, nur f√ºr die Visualisierung
                if (!window.tf) return null; // Fallback, falls tfjs nicht geladen ist
                
                // Erstellen Sie die Vorverarbeitungsfunktionen hier erneut, aber nur f√ºr die Visualisierung
                function audioToMelspectrogramForViz(y) {
                    const DURATION = 3;
                    const TARGET_SAMPLES = 16000 * DURATION;
                    const N_FFT = 1024;
                    const HOP_LENGTH = 512;
                    const N_MELS = 64;

                    if (y.length > TARGET_SAMPLES) {
                        y = y.slice(0, TARGET_SAMPLES);
                    } else if (y.length < TARGET_SAMPLES) {
                        const padding = new Float32Array(TARGET_SAMPLES - y.length).fill(0);
                        const newY = new Float32Array(TARGET_SAMPLES); newY.set(y); newY.set(padding, y.length); y = newY;
                    }
                    return tf.tidy(() => {
                        const stft = tf.signal.stft(tf.tensor1d(y), N_FFT, HOP_LENGTH);
                        const powerSpectrogram = tf.square(tf.abs(stft));
                        const melMatrix = createMelFilterbank(N_MELS, N_FFT / 2 + 1, 16000, 0, 16000 / 2);
                        const melSpectrogram = tf.matMul(powerSpectrogram, melMatrix);
                        const logMelSpectrogram = tf.log(melSpectrogram.add(1e-6));
                        return logMelSpectrogram.expandDims(-1);
                    });
                }
                function createMelFilterbank(numMelBins, numSpectrogramBins, sampleRate, lowerEdgeHz, upperEdgeHz) {
                    const hzToMel = (hz) => 1127.0 * Math.log(1.0 + hz / 700.0);
                    const melToHz = (mel) => 700.0 * (Math.exp(mel / 1127.0) - 1.0);
                    const lowerMel = hzToMel(lowerEdgeHz);
                    const upperMel = hzToMel(upperEdgeHz);
                    const melPoints = tf.linspace(lowerMel, upperMel, numMelBins + 2).arraySync();
                    const hzPoints = melPoints.map(melToHz);
                    const spectrogramBinHz = sampleRate / 2.0 / (numSpectrogramBins - 1);
                    const spectrogramBinEdges = Array.from({ length: numSpectrogramBins }, (_, i) => i * spectrogramBinHz);
                    const melWeights = tf.buffer([numSpectrogramBins, numMelBins]);
                    for (let i = 0; i < numMelBins; i++) {
                        const leftEdge = hzPoints[i], center = hzPoints[i+1], rightEdge = hzPoints[i+2];
                        for (let j = 0; j < numSpectrogramBins; j++) {
                            const specHz = spectrogramBinEdges[j];
                            let weight = 0.0;
                            if (specHz >= leftEdge && specHz <= center) weight = (specHz - leftEdge) / (center - leftEdge);
                            else if (specHz > center && specHz <= rightEdge) weight = (rightEdge - specHz) / (rightEdge - center);
                            if(weight > 0) melWeights.set(weight, j, i);
                        }
                    }
                    return melWeights.toTensor();
                }

                return audioToMelspectrogramForViz(audioClip);
            }

            // --- Alle weiteren Funktionen (createWavBlob, displayResults, drawSpectrogram) bleiben unver√§ndert ---
            // ... (Kopieren Sie den Rest Ihrer Funktionen von createWavBlob bis zum Ende hierher)
            
            function createWavBlob(samples, sampleRate) {
                const buffer = new ArrayBuffer(44 + samples.length * 2);
                const view = new DataView(buffer);
                const writeString = (view, offset, string) => { for (let i = 0; i < string.length; i++) { view.setUint8(offset + i, string.charCodeAt(i)); } };
                writeString(view, 0, 'RIFF');
                view.setUint32(4, 36 + samples.length * 2, true);
                writeString(view, 8, 'WAVE');
                writeString(view, 12, 'fmt ');
                view.setUint32(16, 16, true);
                view.setUint16(20, 1, true);
                view.setUint16(22, 1, true);
                view.setUint32(24, sampleRate, true);
                view.setUint32(28, sampleRate * 2, true);
                view.setUint16(32, 2, true);
                view.setUint16(34, 16, true);
                writeString(view, 36, 'data');
                view.setUint32(40, samples.length * 2, true);
                let offset = 44;
                for (let i = 0; i < samples.length; i++, offset += 2) {
                    const s = Math.max(-1, Math.min(1, samples[i]));
                    view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
                }
                return new Blob([view], { type: 'audio/wav' });
            }

            function displayResults(events) {
                resultsSection.classList.remove('hidden');
                resultsTitle.textContent = `Ergebnisse: ${events.length} Uhu-Rufe gefunden`;
                if (events.length === 0) {
                    resultsSummary.innerHTML = `<div class="bg-blue-100 border-l-4 border-blue-500 text-blue-700 p-4 rounded-md" role="alert"><p>Es wurden keine Ereignisse √ºber dem eingestellten Schwellenwert gefunden.</p></div>`;
                    return;
                }
                events.sort((a, b) => b.prob - a.prob);
                const csvContent = "data:text/csv;charset=utf-8," + "file,start_s,end_s,probability\n" + events.map(e => `${e.file},${(e.start / AUDIO_CONFIG.SAMPLE_RATE).toFixed(2)},${(e.end / AUDIO_CONFIG.SAMPLE_RATE).toFixed(2)},${e.prob.toFixed(3)}`).join("\n");
                const encodedUri = encodeURI(csvContent);
                resultsSummary.innerHTML = `<a href="${encodedUri}" download="uhu_events.csv" class="inline-block bg-green-600 text-white font-bold py-2 px-4 rounded-lg hover:bg-green-700 transition-colors">üìÑ Alle ${events.length} Erkennungen als CSV herunterladen</a>`;
                const clipsToShow = events.slice(0, MAX_CLIPS_TO_SHOW);
                resultsGrid.innerHTML = `<h3 class="col-span-full text-xl font-bold text-gray-800 mt-6 mb-2">Erkannte Clips (Top ${clipsToShow.length})</h3>`;
                clipsToShow.forEach(event => {
                    const card = document.createElement('div');
                    card.className = 'bg-gray-50 p-4 rounded-lg shadow';
                    const specCanvas = document.createElement('canvas');
                    specCanvas.width = 200;
                    specCanvas.height = 128;
                    const audio = new Audio();
                    const blob = createWavBlob(event.audioClip, AUDIO_CONFIG.SAMPLE_RATE);
                    audio.src = URL.createObjectURL(blob);
                    audio.controls = true;
                    audio.className = 'w-full mt-2';
                    card.innerHTML = `
                        <p class="text-sm font-medium truncate" title="${event.file}">${event.file}</p>
                        <p class="text-xs text-indigo-600 font-bold">Wahrscheinlichkeit: ${(event.prob * 100).toFixed(1)}%</p>
                    `;
                    card.appendChild(specCanvas);
                    card.appendChild(audio);
                    resultsGrid.appendChild(card);
                    
                    // Delay spectrogram generation slightly to ensure the canvas is in the DOM
                    setTimeout(async () => {
                        const specTensorForViz = await getSpecForViz(event.audioClip);
                        if (specTensorForViz) {
                            drawSpectrogram(specTensorForViz, specCanvas);
                            tf.dispose(specTensorForViz);
                        }
                    }, 0);
                });
            }

            function drawSpectrogram(spec3D, canvas) {
                tf.tidy(() => {
                    const spec2D = spec3D.squeeze();
                    const specTransposed = spec2D.transpose();
                    const ctx = canvas.getContext('2d');
                    const [height, width] = specTransposed.shape;
                    const canvasWidth = canvas.width, canvasHeight = canvas.height;
                    const specArray = specTransposed.arraySync();
                    let minVal = Infinity, maxVal = -Infinity;
                    for(let i=0; i<height; i++) { for(let j=0; j<width; j++) { if(specArray[i][j] < minVal) minVal = specArray[i][j]; if(specArray[i][j] > maxVal) maxVal = specArray[i][j]; } }
                    const range = maxVal - minVal;
                    const colWidth = canvasWidth / width, rowHeight = canvasHeight / height;
                    const viridis = [ [68, 1, 84], [72, 40, 120], [62, 74, 137], [49, 104, 142], [38, 130, 142], [31, 158, 137], [53, 183, 121], [109, 205, 89], [180, 222, 44], [253, 231, 37] ];
                    const getColor = (value) => {
                        const i = Math.min(Math.max(Math.floor(value * (viridis.length - 1)), 0), viridis.length - 2);
                        const t = value * (viridis.length - 1) - i;
                        const r = Math.floor(viridis[i][0] + t * (viridis[i+1][0] - viridis[i][0]));
                        const g = Math.floor(viridis[i][1] + t * (viridis[i+1][1] - viridis[i][1]));
                        const b = Math.floor(viridis[i][2] + t * (viridis[i+1][2] - viridis[i][2]));
                        return `rgb(${r},${g},${b})`;
                    };
                    ctx.clearRect(0, 0, canvasWidth, canvasHeight);
                    for (let x = 0; x < width; x++) {
                        for (let y = 0; y < height; y++) {
                            const value = specArray[y][x];
                            const normalized = (value - minVal) / range;
                            ctx.fillStyle = getColor(normalized);
                            ctx.fillRect(x * colWidth, canvasHeight - (y + 1) * rowHeight, colWidth, rowHeight);
                        }
                    }
                });
            }
        });
    </script>
</body>
</html>
